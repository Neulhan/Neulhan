<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <link rel="icon" href="../favicon.ico" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <!-- Google tag (gtag.js) -->
        <script
            async
            src="https://www.googletagmanager.com/gtag/js?id=G-TQE5NFT4DN"
        ></script>
        <script>
            window.dataLayer = window.dataLayer || []
            function gtag() {
                dataLayer.push(arguments)
            }
            gtag('js', new Date())

            gtag('config', 'G-TQE5NFT4DN')
        </script>

        
		<link href="../_app/immutable/assets/0.a1438c00.css" rel="stylesheet">
		<link href="../_app/immutable/assets/3.52881d62.css" rel="stylesheet">
		<link rel="modulepreload" href="../_app/immutable/entry/start.8081298f.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/scheduler.7c4769d9.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/singletons.61a86e9c.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/control.f5b05b5f.js">
		<link rel="modulepreload" href="../_app/immutable/entry/app.0729f139.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/preload-helper.a4192956.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/index.cc557082.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/0.67271944.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/each.e59479a4.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/3.fcc6defe.js"><title>Langchain 맛보기</title><!-- HEAD_svelte-11jjeuz_START --><meta property="og:type" content="article"><meta property="og:title" content="Langchain 맛보기"><!-- HEAD_svelte-11jjeuz_END -->
    </head>
    <body data-sveltekit-preload-data="hover">
        <div style="display: contents">  <div class="app flex flex-col sm:flex-row"><div class="w-64 p-4 shrink-0"><div class="logo mb-4" data-svelte-h="svelte-f3eb4u"><a href="/"><img class="w-32" src="/_app/immutable/assets/logo-full-light-transparent.1de22219.svg" alt="neulhan logo"></a></div> <nav class="py-4 flex flex-col"><a class="flex items-center bg-white py-1 px-2 mb-1 hover:bg-slate-100 cursor-pointer" href="https://github.com/Neulhan" target="_blank"><img class="rounded-2xl w-8 mr-2" src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="늘한 소개"> 소개 </a><a class="flex items-center bg-white py-1 px-2 mb-1 hover:bg-slate-100 cursor-pointer" href="https://velog.io/@neulhan" target="_blank"><img class="rounded-2xl w-8 mr-2" src="https://images.velog.io/images/wwwssj0309/post/e2262211-93c1-46a2-b72c-345c5c22a683/1.jpg" alt="늘한 예전 블로그"> 예전 블로그 </a></nav> </div> <main> <article class="container p-4 sm:p-12 mx-auto max-w-3xl bg-white"><div class="content-head"><div class="flex"><h1 class="text-4xl pb-2 font-semibold">Langchain 맛보기</h1></div> <p class="opacity-50 pb-2">2023-11-08</p></div> <div class="my-4 flex"><button class="category rounded-md py-1 px-2 align-middle mr-2 bg-white font-medium svelte-17b5yfn">#langchain </button><button class="category rounded-md py-1 px-2 align-middle mr-2 bg-white font-medium svelte-17b5yfn">#llm </button></div> <div class="md py-4"><p data-svelte-h="svelte-1arc6h6">생성형 AI 는 올해 아주 핫하다.
나는 개발자로 일하면서 꽤 오랜 시간동안 곁눈질 하다가 이제서야 LLM 을 제대로 들여다보고 있다.
LLM 어플리케이션을 만들기 위해 뒤늦게 기술들을 살펴보고 있는 경험을 공유한다.</p> <h3 data-svelte-h="svelte-17pkcfn">LLM</h3> <p data-svelte-h="svelte-407xd8">몇 달 전에 “ChatGPT Prompt Engineering for Developers” 라는 강의를 보면서 LLM 에 대한 개념은 좀 탑재했었다.
LLM 은 Large Language Model 의 약자이다.
LLM 은 쉽게 말해 다음에 나올 단어를 예측하는 거대한 언어모델이다.</p> <p data-svelte-h="svelte-1i1fayc">AI 모델을 직접 훈련시키는 건 비용이 아주 많이 들고, 전문인력이 필요한 일이다.
그런데 LLM 은 prompt engineering 와 fine tuning 을 통해서 간단하게 AI 를 다룰 수 있게 해주었다.</p> <p data-svelte-h="svelte-1wrasyr">다음에 나올 단어를 예측하는건 LLM 이 하고, 우리는 LLM 에게 맥락만 전달해주면 된다.</p> <h2 data-svelte-h="svelte-7pmgah">Langchain</h2> <p data-svelte-h="svelte-ulq2ol">최근에는 langchain 에 관한 내용을 보았다.
langchain 은 LLM 을 이용해서 어플리케이션을 만들 수 있는 Chain 을 제공한다.</p> <p data-svelte-h="svelte-gbrer7"><img src="https://neulhan-blog.s3.ap-northeast-2.amazonaws.com/images/Langchain-%EB%A7%9B%EB%B3%B4%EA%B8%B0/2023-11-12-18-05-55.png" alt="langchain ecosystem"></p> <p data-svelte-h="svelte-vdmucu">Langchain 은 public/private 한 데이터를 가져와서 사용자의 질문에 대답하거나, 특정 기능을 구현하는데 특화된 프레임워크이다.</p> <h3 data-svelte-h="svelte-11r4c1t">Agent</h3> <p data-svelte-h="svelte-1ovxi98">Agent 는 tool 을 직접 사용해서 작업을 수행한다.
예를 들어 “구글에서 검색하기” 라는 함수를 만들어서 툴로 쥐어주면,
자기가 알아서 필요할 때 구글에서 검색해서 결과를 가져다가 쓴다.</p> <p data-svelte-h="svelte-t0n8vg">verbose 를 True 로 주면 자기가 무슨 생각 하면서 뭘 하고 있는지 줄줄이 읊는데 보고있으면 꽤나 신기하고 재미있다.</p> <pre class="language-python"><!-- HTML_TAG_START --><code class="language-python">tool_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
tools <span class="token operator">=</span> load_tools<span class="token punctuation">(</span>tool_names<span class="token punctuation">)</span>

agent <span class="token operator">=</span> initialize_agent<span class="token punctuation">(</span>
    tools<span class="token punctuation">,</span> llm<span class="token punctuation">,</span> agent<span class="token operator">=</span>AgentType<span class="token punctuation">.</span>ZERO_SHOT_REACT_DESCRIPTION<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span></code><!-- HTML_TAG_END --></pre> <h3 data-svelte-h="svelte-ltauy0">Token Limit</h3> <p data-svelte-h="svelte-1fa8tmr">Token Limit 은 간단하게 말하면 LLM 이 한 번에 처리할 수 있는 용량에 대한 제한이다.<br>
Prompt 에 모든 정보를 다 넣으면 LLM 이 처리할 수 있는 한도를 넘기기 때문에 처리가 불가능하다.
그래서 전통적인 벡터 유사도에 따른 검색을 같이 활용한다.<br>
OpenAI 의 <code>gpt-3.5-turbo</code> 의 경우 4K 의 토큰 제한을 가지고 있다.</p> <pre class="language-python"><!-- HTML_TAG_START --><code class="language-python"><span class="token punctuation">&#123;</span>
    <span class="token string">"error"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"message"</span><span class="token punctuation">:</span> <span class="token string">"This model's maximum context length is 4097 tokens. However, your messages resulted in 9129 tokens. Please reduce the length of the messages."</span><span class="token punctuation">,</span>
        <span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"invalid_request_error"</span><span class="token punctuation">,</span>
        <span class="token string">"param"</span><span class="token punctuation">:</span> <span class="token string">"messages"</span><span class="token punctuation">,</span>
        <span class="token string">"code"</span><span class="token punctuation">:</span> <span class="token string">"context_length_exceeded"</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span></code><!-- HTML_TAG_END --></pre> <h3 data-svelte-h="svelte-14zrsmm">Vector Store</h3> <p data-svelte-h="svelte-ytxmva">Vector Store 는 벡터 데이터베이스이다.<br>
전통적인 검색엔진을 구성할 때, 문서들을 벡터화 한 다음에 문서 사이의 벡터 유사도를 통해 유사도가 높은 문서를 추천한다.<br>
LLM 에 모든 문서를 parameter 로 보낼 수 없기 때문에, Vector Store 에서 한 번 검색한 결과를 LLM 에 넘겨주는 방식을 많이 사용한다.<br> <code>Pinecone</code> 이라는 툴이 요즘은 대세인 듯 하다.</p> <p data-svelte-h="svelte-ilktvr">langchain 에서는 이 Vector Store 를 쓰는 걸 너무너무 쉽고 간단하게 만들어놨다. document 랑 embedding 만 넣으면 그냥 저장이 되고, 꺼내서 쓰는것도 너무 편하다.</p> <pre class="language-python"><!-- HTML_TAG_START --><code class="language-python">Pinecone<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>
    documents<span class="token operator">=</span>documents<span class="token punctuation">,</span>
    embedding<span class="token operator">=</span>embeddings<span class="token punctuation">,</span>
    index_name<span class="token operator">=</span><span class="token string">"farmandgood-doc-index"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span></code><!-- HTML_TAG_END --></pre> <h3 data-svelte-h="svelte-1oyhtpt">Embedding</h3> <p data-svelte-h="svelte-1acxsnh">Vector Store 에 문서를 벡터화 해서 적재하는걸 Embedding 이라고 한다.<br>
이 과정도 주로 AI 모델을 통해 이루어진다.</p> <p data-svelte-h="svelte-153zwt2">질문에 알맞은 문서를 벡터 검색으로 찾아내기 위해서는 임베딩의 성능도 아주 중요하다. 따라서 LLM 어플리케이션 개발을 할 때는 임베딩 모델을 이것저것 바꿔가면서 테스트해보는 모양이다.<br>
가장 일반적인 Embedding 모델은 OpenAI 의 ada-02 라고 하는데, 문서를 1536 차원의 벡터로 임베딩해준다.</p> <pre class="language-python"><!-- HTML_TAG_START --><code class="language-python">embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span>
    openai_api_key<span class="token operator">=</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span></code><!-- HTML_TAG_END --></pre> <h3 data-svelte-h="svelte-1dk0b6r">Text Splitting</h3> <p data-svelte-h="svelte-tf6egm">1만자 분량의 문서가 있으면 이 문서를 하나의 문서로 Embedding 하지는 않는다.<br>
문서 안에서도 내용들이 다양하기에, 하나의 문서로 임베딩 되면 유사도 추천이 부정확해질것.<br>
그래서 문서를 잘라서 Embedding 하도록 하는걸 Text Splitting 이라고 한다.</p> <p data-svelte-h="svelte-1q1vicy">1만자 분량의 문서를 1,000 자 단위로, 100 자의 share 영역을 두고 자르는 식이다.</p> <pre class="language-python"><!-- HTML_TAG_START --><code class="language-python">text_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span>
    chunk_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> chunk_overlap<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> separators<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"&#92;n&#92;n"</span><span class="token punctuation">,</span> <span class="token string">"&#92;n"</span><span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span></code><!-- HTML_TAG_END --></pre> <h2 data-svelte-h="svelte-uq1p97">다음 스텝</h2> <p data-svelte-h="svelte-3n5uzt">이제 Langchain 으로 직접 어플리케이션을 구현하면서 실제로 구현하면서 이슈가 되는 것들을 좀 살펴보자.<br>
Summarizing, Document QnA 같은 기능은 구현이 너무 쉬워서 이쪽 위주로 어플리케이션을 만들어봐도 좋을 것 같다.</p></div> </article></main> </div> 
			
			<script>
				{
					__sveltekit_83z6fm = {
						base: new URL("..", location).pathname.slice(0, -1),
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("../_app/immutable/entry/start.8081298f.js"),
						import("../_app/immutable/entry/app.0729f139.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 3],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
    </body>
</html>
